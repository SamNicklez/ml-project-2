{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Such\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Installation on Google Colab\n",
    "try:\n",
    "    import os\n",
    "    import google.colab\n",
    "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch', 'torchvision'])\n",
    "    subprocess.run(['mkdir', '-p', 'datasets'])\n",
    "    subprocess.run(['wget', '-nc', '--no-check-certificate',\n",
    "                   'https://download.pytorch.org/tutorial/hymenoptera_data.zip', '-P', 'datasets'])\n",
    "    subprocess.run(\n",
    "        ['unzip', '-u', 'datasets/hymenoptera_data.zip', '-d' 'datasets'])\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26b3194e590>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "torch.manual_seed(360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/'\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train'), train_transforms)\n",
    "val_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'valid'), val_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Pretrained Model\n",
    "\n",
    "We use a pretrained `ResNet18` neural network model with its final layer replaced with a fully connected layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch.callbacks import Freezer\n",
    "\n",
    "lrscheduler = LRScheduler(\n",
    "    policy='StepLR', step_size=7, gamma=0.1)\n",
    "\n",
    "checkpoint = Checkpoint(\n",
    "    f_params='best_model.pt', monitor='valid_acc_best')\n",
    "\n",
    "freezer = Freezer(lambda x: not x.startswith('model.fc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skorch.NeuralNetClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    PretrainedModel,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    lr=0.001,\n",
    "    batch_size=3,\n",
    "    max_epochs=25,\n",
    "    module__output_features=5,\n",
    "    optimizer=optim.SGD,\n",
    "    optimizer__momentum=0.9,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__num_workers=2,\n",
    "    iterator_valid__num_workers=2,\n",
    "    train_split=predefined_split(val_ds),\n",
    "    callbacks=[lrscheduler, checkpoint, freezer],\n",
    "    classes=['Baseball', 'Basketball', 'Football', 'Hockey', 'Volleyball'],  # Fix for my error\n",
    "    device='cpu' # Change to 'cuda' if you have a GPU\n",
    ")\n",
    "\n",
    "# 95% acc with lr=0.001 and batch size of 4\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samue\\Documents\\ml-project-2\\.conda\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Samue\\Documents\\ml-project-2\\.conda\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss    cp      lr      dur\n",
      "-------  ------------  -----------  ------------  ----  ------  -------\n",
      "      1        \u001b[36m1.5287\u001b[0m       \u001b[32m0.8603\u001b[0m        \u001b[35m0.4927\u001b[0m     +  0.0010  64.3417\n",
      "      2        \u001b[36m1.1403\u001b[0m       0.8329        \u001b[35m0.4357\u001b[0m        0.0010  60.4716\n",
      "      3        \u001b[36m0.9670\u001b[0m       0.8603        \u001b[35m0.4002\u001b[0m        0.0010  68.7568\n",
      "      4        1.0358       \u001b[32m0.8959\u001b[0m        \u001b[35m0.2799\u001b[0m     +  0.0010  58.0561\n",
      "      5        \u001b[36m0.9049\u001b[0m       \u001b[32m0.8986\u001b[0m        \u001b[35m0.2737\u001b[0m     +  0.0010  61.9801\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "if not os.path.isfile('best_model.pt'):\n",
    "    net.fit(train_ds, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samue\\Documents\\ml-project-2\\.conda\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Samue\\Documents\\ml-project-2\\.conda\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Football, Actual: Baseball, filename: baseball4.jpg\n",
      "Predicted: Basketball, Actual: Baseball, filename: baseball5.jpg\n",
      "Predicted: Volleyball, Actual: Basketball, filename: basketball3.jpg\n",
      "Accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "model_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    PretrainedModel,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    module__output_features=5,\n",
    ")\n",
    "\n",
    "# LOAD MODEL FROM FILE\n",
    "net.initialize()\n",
    "net.load_params(f_params='best_model.pt')\n",
    "\n",
    "test_dir = 'data/test/'\n",
    "test_images = os.listdir(test_dir)\n",
    "\n",
    "classes = ['Baseball', 'Basketball', 'Football', 'Hockey', 'Volleyball']\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Test the model\n",
    "for img_name in test_images:\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    img = Image.open(img_path)\n",
    "    img_transformed = model_transforms(img).unsqueeze(0)\n",
    "\n",
    "    # Extract class name from filename by removing digits and extension\n",
    "    class_name = ''.join(filter(str.isalpha, img_name.split('.')[0])).capitalize()\n",
    "\n",
    "    # Prediction\n",
    "    output = net.predict(img_transformed)\n",
    "    predicted = output[0]\n",
    "\n",
    "    # Check prediction\n",
    "\n",
    "    if predicted == class_to_idx[class_name]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(f'Predicted: {classes[predicted]}, Actual: {class_name}, filename: {img_name}')\n",
    "    total += 1\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
