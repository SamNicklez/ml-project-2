{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Project 2\n",
    "## Training/validation/testing\n",
    "\n",
    "Requirements:\n",
    "\n",
    "- Code/instructions for loading\n",
    "saved model and running model\n",
    "on 10 example cases (e.g.,\n",
    "images)\n",
    "\n",
    "- Okay to document results on\n",
    "these 10 cases here (rather than\n",
    "including them as part of\n",
    "training/validation/testing\n",
    "notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "Code should just be plug and play, though ensure the following:\n",
    "\n",
    "- `best_model.pt` is in the root directory\n",
    "- the test images are in a folder called `testImages` and the folder is in the root directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Installation on Google Colab\n",
    "try:\n",
    "    import os\n",
    "    import google.colab\n",
    "    subprocess.run(['python', '-m', 'pip', 'install', 'skorch', 'torchvision'])\n",
    "    subprocess.run(['mkdir', '-p', 'datasets'])\n",
    "    subprocess.run(['wget', '-nc', '--no-check-certificate',\n",
    "                   'https://download.pytorch.org/tutorial/hymenoptera_data.zip', '-P', 'datasets'])\n",
    "    subprocess.run(\n",
    "        ['unzip', '-u', 'datasets/hymenoptera_data.zip', '-d' 'datasets'])\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2c9d85b4e70>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from urllib import request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.callbacks import Checkpoint\n",
    "from skorch.callbacks import Freezer\n",
    "\n",
    "torch.manual_seed(360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Football, Actual: Baseball, filename: baseball4.jpg\n",
      "Predicted: Basketball, Actual: Baseball, filename: baseball5.jpg\n",
      "Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained=True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    PretrainedModel,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    module__output_features=5,\n",
    ")\n",
    "\n",
    "net.initialize()\n",
    "net.load_params(f_params='best_model.pt')\n",
    "\n",
    "test_dir = 'testImages'\n",
    "test_images = os.listdir(test_dir)\n",
    "\n",
    "classes = ['Baseball', 'Basketball', 'Football', 'Hockey', 'Volleyball']\n",
    "class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for img_name in test_images:\n",
    "    img_path = os.path.join(test_dir, img_name)\n",
    "    img = Image.open(img_path)\n",
    "    img_transformed = model_transforms(img).unsqueeze(0)\n",
    "\n",
    "    # Extract class name from filename by removing digits and extension\n",
    "    class_name = ''.join(filter(str.isalpha, img_name.split('.')[0])).capitalize()\n",
    "\n",
    "    # Predict\n",
    "    output = net.predict(img_transformed)\n",
    "    predicted = output[0]\n",
    "\n",
    "    # Check prediction\n",
    "    if predicted == class_to_idx[class_name]:\n",
    "        correct += 1\n",
    "    else:\n",
    "        print(f'Predicted: {classes[predicted]}, Actual: {class_name}, filename: {img_name}')\n",
    "    total += 1\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
